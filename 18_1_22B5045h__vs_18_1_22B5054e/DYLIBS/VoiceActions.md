## VoiceActions

> `/System/Library/PrivateFrameworks/VoiceActions.framework/VoiceActions`

```diff

-52.0.0.0.0
-  __TEXT.__text: 0x118e20
-  __TEXT.__auth_stubs: 0x2830
-  __TEXT.__objc_methlist: 0x12b4
-  __TEXT.__const: 0x7612
-  __TEXT.__cstring: 0x907f
-  __TEXT.__swift5_typeref: 0x1f81
-  __TEXT.__swift5_reflstr: 0x3dd7
+54.0.0.0.0
+  __TEXT.__text: 0x116d78
+  __TEXT.__auth_stubs: 0x2780
+  __TEXT.__objc_methlist: 0x1020
+  __TEXT.__const: 0x7642
+  __TEXT.__cstring: 0x8e09
+  __TEXT.__swift5_typeref: 0x1f87
+  __TEXT.__swift5_reflstr: 0x3df7
   __TEXT.__swift5_assocty: 0x1c8
-  __TEXT.__constg_swiftt: 0x75d0
-  __TEXT.__swift5_fieldmd: 0x3fe0
-  __TEXT.__swift5_proto: 0x504
-  __TEXT.__swift5_types: 0x3d0
-  __TEXT.__oslogstring: 0x1d8f
+  __TEXT.__constg_swiftt: 0x764c
+  __TEXT.__swift5_fieldmd: 0x4014
+  __TEXT.__swift5_proto: 0x508
+  __TEXT.__swift5_types: 0x3d4
+  __TEXT.__oslogstring: 0x1d13
   __TEXT.__swift5_capture: 0x87c
   __TEXT.__swift5_builtin: 0xc8
   __TEXT.__swift5_protos: 0x28
   __TEXT.__swift5_mpenum: 0x24
-  __TEXT.__gcc_except_tab: 0x121c
-  __TEXT.__dlopen_cstrs: 0xb7
-  __TEXT.__unwind_info: 0x45c0
-  __TEXT.__eh_frame: 0x85bc
-  __TEXT.__objc_classname: 0xcd
-  __TEXT.__objc_methname: 0x2ebe
-  __TEXT.__objc_methtype: 0xff1
-  __TEXT.__objc_stubs: 0x18a0
-  __DATA_CONST.__got: 0x7a8
-  __DATA_CONST.__const: 0x6e8
-  __DATA_CONST.__objc_classlist: 0x4b8
-  __DATA_CONST.__objc_protolist: 0x30
+  __TEXT.__gcc_except_tab: 0x10b0
+  __TEXT.__unwind_info: 0x4528
+  __TEXT.__eh_frame: 0x86bc
+  __TEXT.__objc_classname: 0x55
+  __TEXT.__objc_methname: 0x1e58
+  __TEXT.__objc_methtype: 0xb96
+  __TEXT.__objc_stubs: 0xf80
+  __DATA_CONST.__got: 0x760
+  __DATA_CONST.__const: 0x5a0
+  __DATA_CONST.__objc_classlist: 0x4a8
+  __DATA_CONST.__objc_protolist: 0x20
   __DATA_CONST.__objc_imageinfo: 0x8
-  __DATA_CONST.__objc_selrefs: 0xbb8
+  __DATA_CONST.__objc_selrefs: 0x928
   __DATA_CONST.__objc_protorefs: 0x18
-  __DATA_CONST.__objc_superrefs: 0x28
-  __DATA_CONST.__objc_arraydata: 0x30
-  __AUTH_CONST.__auth_got: 0x1430
-  __AUTH_CONST.__auth_ptr: 0x990
-  __AUTH_CONST.__const: 0x51d8
-  __AUTH_CONST.__cfstring: 0x560
-  __AUTH_CONST.__objc_const: 0xbc28
-  __AUTH_CONST.__objc_intobj: 0x18
-  __AUTH_CONST.__objc_dictobj: 0x50
-  __AUTH.__objc_data: 0x4190
-  __AUTH.__data: 0x9310
-  __DATA.__objc_ivar: 0xdc
-  __DATA.__data: 0x17f8
-  __DATA.__bss: 0x9d98
+  __DATA_CONST.__objc_superrefs: 0x10
+  __AUTH_CONST.__auth_got: 0x13d0
+  __AUTH_CONST.__auth_ptr: 0x938
+  __AUTH_CONST.__const: 0x51b8
+  __AUTH_CONST.__cfstring: 0x3e0
+  __AUTH_CONST.__objc_const: 0xb168
+  __AUTH.__objc_data: 0x4140
+  __AUTH.__data: 0x93e0
+  __DATA.__objc_ivar: 0x6c
+  __DATA.__data: 0x1748
+  __DATA.__bss: 0x9db8
   __DATA.__common: 0x2d8
   - /System/Library/Frameworks/AVFAudio.framework/AVFAudio
   - /System/Library/Frameworks/Accelerate.framework/Accelerate

   - /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition
   - /System/Library/PrivateFrameworks/Espresso.framework/Espresso
   - /System/Library/PrivateFrameworks/InternalSwiftProtobuf.framework/InternalSwiftProtobuf
-  - /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking
   - /usr/lib/libSystem.B.dylib
   - /usr/lib/libc++.1.dylib
   - /usr/lib/libobjc.A.dylib

   - /usr/lib/swift/libswiftsimd.dylib
   - /usr/lib/swift/libswiftsys_time.dylib
   - /usr/lib/swift/libswiftunistd.dylib
-  Functions: 5590
-  Symbols:   479
-  CStrings:  1982
+  Functions: 5529
+  Symbols:   450
+  CStrings:  1734
 
Symbols:
+ _swift_unknownObjectRelease_n
- _dispatch_assert_queue$V2
- __sl_dlopen
- _objc_opt_class
- _OBJC_CLASS_$_NSMutableData
- _OBJC_CLASS_$_VATSpeechRecognitionResult
- _NSLocalizedDescriptionKey
- _dispatch_time
- ___kCFBooleanTrue
- _objc_getClass
- _OBJC_CLASS_$_NSSet
- ___kCFBooleanFalse
- _OBJC_METACLASS_$_VATSpeechTranscription
- __Block_object_dispose
- _dispatch_async
- _OBJC_CLASS_$_NSConstantDictionary
- _OBJC_CLASS_$_NSConstantIntegerNumber
- _OBJC_METACLASS_$_VATSpeechRecognitionResult
- _OBJC_CLASS_$_VATSpeechTranscription
- _objc_retain_x4
- _NSLocalizedFailureReasonErrorKey
- _objc_retain_x3
- ___objc_personality_v0
- _objc_retainBlock
- _OBJC_CLASS_$_NSCharacterSet
- _OBJC_CLASS_$_NSURL
- _OBJC_METACLASS_$_VATSpeechRecognizer
- _OBJC_CLASS_$_VATSpeechRecognizer
- _dispatch_queue_attr_make_with_qos_class
- _abort_report_np
- _dispatch_queue_create
CStrings:
+ "Stop(): Ignoring when already in progress"
+ "Stop(): listening task completed, success=%!s(MISSING)"
+ "Stop(): done"
+ "Stop(): set requestInfo to nil after stopping spotter"
+ "threadSafeBool"
+ "Stop(): starting"
+ "start Flexibile spotter: %!s(MISSING)"
+ "_TtC12VoiceActions19ThreadSafeBoolActor"
+ "Stop(): processing was stopped, break out of StartProcessingAudioToAudio()"
+ "Could not create keyword %!s(MISSING)"
+ "state"
- "@\"NSLocale\""
- "hash"
- "@\"_EARSpeechRecognizer\""
- "bestTranscription"
- "stable"
- "setFinal:"
- "Td,R,N,V_maxConfidence"
- "Error creating EARRecognizer"
- "T@\"NSLocale\",R,N,V_language"
- "v28@0:8B16@?20"
- "resultWithResults:locale:modelVersion:isFinal:"
- "v40@0:8@16Q24@32"
- "resultWithPackage:locale:modelVersion:isFinal:"
- "dataWithData:"
- "_recognitionHandler"
- "supportedByQuasarConfig:"
- "v80@0:8@\"_EARSpeechRecognizer\"16q24q32d40@\"NSArray\"48d56q64d72"
- "conformsToProtocol:"
- "2nd pass timed out in 3 secs\n"
- "audioDataWithInjectedSilence"
- "URLByAppendingPathComponent:"
- "initWithResults:locale:modelVersion:isFinal:"
- "initWithBytesNoCopy:length:freeWhenDone:"
- "detectUtterances"
- "stringWithString:"
- "T@\"NSArray\",&,N,V_transcriptions"
- "2nd pass failed, error=%!@(MISSING)"
- "_language"
- "_EARTransformUtil"
- "T@\"NSString\",R,C"
- "emptyResultWithLocale:isFinal:"
- "v72@0:8@16q24q32d40@48d56q64"
- "performSelector:withObject:withObject:"
- "\x13"
- "Q16@0:8"
- "Unable to find class %!s(MISSING)"
- "initWithAssetPath:language:"
- "recognizer"
- "v32@0:8@16d24"
- "superclass"
- "@56@0:8@16@24d32d40d48"
- "addSpeechAudioData:"
- "setModelVersion:"
- "Dictation"
- "setAudioDataWithInjectedSilence:"
- "v32@0:8@\"_EARSpeechRecognizer\"16@\"_EARSpeechRecognition\"24"
- "T@\"NSData\",&,N,V_audioDataWithInjectedSilence"
- "v48@0:8@16@24@32@40"
- "TB,R,N,GisLowConfidence,V_lowConfidence"
- "isStable"
- "_sampleRate"
- "wakeup"
- "initWithPackage:locale:modelVersion:isFinal:"
- "2nd pass failed, error=%!s(MISSING)\n"
- "@\"_EARSpeechRecognitionAudioBuffer\""
- "localeWithLocaleIdentifier:"
- "_recognizer"
- "_detectedSpeechEndpoint"
- "speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:acousticEndpointerScore:"
- "endAudioTime"
- "_maxConfidence"
- "Initializing recognition with config based formatter"
- "self"
- "Error creating recognizer\n"
- "modelVersion"
- "sanitizedFormattedString"
- "hatToQsrString:"
- "appendData:"
- "B24@0:8@\"Protocol\"16"
- "speechRecognizer:didRecognizeVoiceCommandCandidatePackage:"
- "@44@0:8@16@24@32B40"
- "B24@0:8@16"
- "modelURL"
- "v72@0:8@\"_EARSpeechRecognizer\"16q24q32d40@\"NSArray\"48d56q64"
- "SFEntitledAssetConfig"
- "isKindOfClass:"
- "isLowConfidence"
- "speechRecognizer:didRecognizeFinalResults:"
- "T@?,C,N,V_recognitionHandler"
- "T@\"NSString\",&,N,V_modelVersion"
- "firstPartialTime"
- "sharedInstance"
- "TB,N,GisStable,V_stable"
- "setWithObject:"
- "com.apple.mind.voiceactions"
- "fileURLWithPath:isDirectory:"
- "setHighPriority:"
- "initEmptyResultWithLocale:isFinal:"
- "speechRecognizer:didFinishRecognitionWithError:"
- "endAudio"
- "mini.json"
- "TB,N,GisFinal,V_final"
- "creating EARRecognizer"
- "_modelVersion"
- "setLocale:"
- "_confidence"
- "v80@0:8@16q24q32d40@48d56q64d72"
- "locale"
- "v32@0:8@\"_EARSpeechRecognizer\"16@\"NSError\"24"
- "_locale"
- "speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:"
- "@32@0:8:16@24"
- "performSelector:withObject:"
- "Missing file or cannot read: %!@(MISSING)"
- "cancelRecognition"
- "tokens"
- "enableParallelLoading"
- "speechRecognizer:didProduceLoggablePackage:"
- "T@\"NSURL\",R,N,V_modelURL"
- "VATSpeechTranscription"
- "transcriptions"
- "Missing file or cannot read: %!s(MISSING)\n"
- "dataWithBytes:length:"
- "Stop keyword spotter, success=%!s(MISSING)"
- "recognitionHandler"
- "initWithLanguage:"
- "B24@0:8:16"
- "Error creating recognizer from \"%!s(MISSING)\"\n"
- "installedAssetWithConfig:"
- "^{_NSZone=}16@0:8"
- "_audioDataWithInjectedSilence"
- "_EARSpeechModelInfo"
- "string"
- "v32@0:8@16@24"
- "T#,R"
- "_lowConfidence"
- "stringByTrimmingCharactersInSet:"
- "Vv16@0:8"
- "isEqual:"
- "@28@0:8@16B24"
- "_transcriptions"
- "debugDescription"
- "_finalResult"
- "2nd pass Timed out"
- "@\"NSData\""
- "com.apple.mind.voiceactions.ear"
- "_transcriptionWithResult:locale:"
- "Td,R,N,V_minConfidence"
- "final"
- "softlink:r:path:/System/Library/Frameworks/Speech.framework/Speech"
- "No speech recognized"
- "Empty recognition"
- "Error creating EARRecognizer from \"%!@(MISSING)\""
- "firstObject"
- "speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:"
- "_task"
- "runRecognitionWithResultStream:language:task:samplingRate:"
- "VoiceActions/VACTCEncoder.swift"
- "speechRecognizer:didRecognizeRawEagerRecognitionCandidate:"
- "localeIdentifier"
- "speechRecognizer:didRecognizePartialResult:"
- "triggerServerSideEndPointer"
- "firstSampleTime"
- "speechRecognizer:didProcessAudioDuration:"
- "@?"
- "isMemberOfClass:"
- "B24@0:8#16"
- "setDetectUtterances:"
- "@\"NSObject<OS_dispatch_queue>\""
- "T@\"NSString\",R,N,V_modelVersion"
- "setSamplingRateFilter:"
- "version"
- "v36@0:8B16@20@?28"
- "VATSpeechRecognizer"
- "First audio to first partial = %!l(MISSING)f"
- "formattedString"
- "@\"NSString\"16@0:8"
- "_minConfidence"
- "en-US"
- "Initializing recognition with Quasar formatter"
- "v32@0:8@\"_EARSpeechRecognizer\"16@\"_EARSpeechRecognitionResult\"24"
- "release"
- "speechRecognizer:didRecognizePartialResultPackage:"
- "\x02\x12A\x15"
- "TQ,R"
- "initWithConfiguration:overrides:overrideConfigFiles:language:activeConfiguration:modelLoadingOptions:enableSpeakerCodeTraining:"
- "whitespaceCharacterSet"
- "set requestInfo to nil after stopping spotter"
- "End audio to final \"%!@(MISSING)\" = %!l(MISSING)f"
- "recognitionResultsWithAudioData:userProfileData:language:task:samplingRate:extraLanguageModel:"
- "@40@0:8:16@24@32"
- "containsString:"
- "creating EARRecognizer from custom path \"%!@(MISSING)\""
- "_formattedString"
- "nBestResults"
- "@24@0:8:16"
- "lowConfidence"
- "v40@0:8@\"_EARSpeechRecognizer\"16Q24@\"NSDictionary\"32"
- "autorelease"
- "maxConfidence"
- "language"
- "minConfidence"
- "\\determiner"
- "setStable:"
- "speechRecognizer:didRecognizeFinalResultCandidatePackage:"
- "setRecognitionHandler:"
- "isProxy"
- "_EARSpeechRecognitionActiveConfiguration"
- "T@\"NSString\",R,C,N,V_sanitizedFormattedString"
- "retainCount"
- "Got 2nd pass \"%!s(MISSING)\" in %!f(MISSING) secs!\n"
- "second pass: %!s(MISSING)\n"
- "_buffer"
- "v32@0:8@\"_EARSpeechRecognizer\"16d24"
- "_recognizedResult:error:"
- "setTranscriptions:"
- "array"
- "_stable"
- "SFEntitledAssetManager"
- "_recognitionQueue"
- "NSObject"
- "_EARSpeechRecognizer"
- "_EARFormatter"
- "setRecognitionReplacements:"
- "speechRecognizer:didRecognizePartialResultNbest:"
- "Td,R,N,V_confidence"
- "speechRecognizer:didReportStatus:statusContext:"
- "T@\"NSString\",?,R,C"
- "keepANEModelLoaded"
- "startRecognitionWithAutoStop:pcmBuffer:resultHandler:"
- "errorWithDomain:code:userInfo:"
- "T@\"NSLocale\",C,N,V_locale"
- "@\"_EARSpeechRecognitionResultPackage\""
- "initWithModelURL:language:modelVersion:"
- "_modelURL"
- "v48@0:8@\"_EARSpeechRecognizer\"16@\"NSArray\"24@\"NSArray\"32@\"NSArray\"40"
- "setConcatenateUtterances:"
- "VoiceActions/VAResultGenerator.swift"
- "_final"
- "_sanitizedFormattedString"
- "performSelector:"
- "Wake up"
- "VATSpeechRecognitionResult"
- "startRecognitionWithAutoStop:resultHandler:"
- "stringByAppendingPathComponent:"
- "Datapack = %!@(MISSING)/%!@(MISSING)"
- "T@\"NSString\",R,C,N,V_formattedString"
- "addAudioSampleData:"
- "Got 2nd pass \"%!@(MISSING)\" in %!f(MISSING) secs!"
- "retain"
- "initWithFormattedString:locale:confidence:minConfidence:maxConfidence:"
- "speechRecognizer:didRecognizeFinalResultPackage:"
- "zone"
- "softlink:r:path:/System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition"
- "First audio to final \"%!@(MISSING)\" = %!l(MISSING)f"
- "_EARSpeechRecognitionResultStream"
- "v32@0:8@\"_EARSpeechRecognizer\"16@\"_EARSpeechRecognitionResultPackage\"24"
- "#16@0:8"
- "setTaskTypeFilter:"
- "setRecognizer:"
- "@?16@0:8"
- "T@\"NSLocale\",R,N,V_locale"
- "v32@0:8@\"_EARSpeechRecognizer\"16@\"NSArray\"24"
- "v32@?0@\"VATSpeechRecognitionResult\"8@\"NSData\"16@\"NSError\"24"
- "class"
- "T@\"VATSpeechRecognizer\",N"

```
