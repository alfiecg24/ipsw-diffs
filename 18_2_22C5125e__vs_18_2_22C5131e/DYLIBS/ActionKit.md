## ActionKit

> `/System/Library/PrivateFrameworks/ActionKit.framework/ActionKit`

```diff

-3216.0.6.0.0
-  __TEXT.__text: 0x36b3f4
+3217.0.4.0.0
+  __TEXT.__text: 0x36c464
   __TEXT.__auth_stubs: 0x4800
   __TEXT.__delay_helper: 0x110
-  __TEXT.__objc_methlist: 0x1e2f4
+  __TEXT.__objc_methlist: 0x1e344
   __TEXT.__const: 0x266f8
-  __TEXT.__cstring: 0x4d600
+  __TEXT.__cstring: 0x4d935
   __TEXT.__constg_swiftt: 0x16ac
-  __TEXT.__swift5_typeref: 0x2abd
+  __TEXT.__swift5_typeref: 0x2add
   __TEXT.__swift5_builtin: 0x17c
   __TEXT.__swift5_reflstr: 0x1031
   __TEXT.__swift5_fieldmd: 0xe30

   __TEXT.__swift5_capture: 0x31c
   __TEXT.__swift5_protos: 0x14
   __TEXT.__swift5_mpenum: 0x24
-  __TEXT.__oslogstring: 0x365f
-  __TEXT.__gcc_except_tab: 0x3d2c
-  __TEXT.__dlopen_cstrs: 0x2720
+  __TEXT.__oslogstring: 0x3647
+  __TEXT.__gcc_except_tab: 0x3d6c
+  __TEXT.__dlopen_cstrs: 0x2722
   __TEXT.__ustring: 0x385c
-  __TEXT.__unwind_info: 0xce80
+  __TEXT.__unwind_info: 0xcea0
   __TEXT.__eh_frame: 0x5158
-  __TEXT.__objc_classname: 0x5a95
-  __TEXT.__objc_methname: 0x3f5ea
-  __TEXT.__objc_methtype: 0x9c35
-  __TEXT.__objc_stubs: 0x2a420
-  __DATA_CONST.__got: 0x3688
-  __DATA_CONST.__const: 0x1d408
-  __DATA_CONST.__objc_classlist: 0x1a48
+  __TEXT.__objc_classname: 0x5a8f
+  __TEXT.__objc_methname: 0x3f362
+  __TEXT.__objc_methtype: 0x98e6
+  __TEXT.__objc_stubs: 0x2a440
+  __DATA_CONST.__got: 0x3690
+  __DATA_CONST.__const: 0x1d430
+  __DATA_CONST.__objc_classlist: 0x1a50
   __DATA_CONST.__objc_nlclslist: 0x8
   __DATA_CONST.__objc_catlist: 0x108
-  __DATA_CONST.__objc_protolist: 0x4e0
+  __DATA_CONST.__objc_protolist: 0x4d8
   __DATA_CONST.__objc_imageinfo: 0x8
-  __DATA_CONST.__objc_selrefs: 0xea78
+  __DATA_CONST.__objc_selrefs: 0xea68
   __DATA_CONST.__objc_protorefs: 0x190
-  __DATA_CONST.__objc_superrefs: 0xc58
+  __DATA_CONST.__objc_superrefs: 0xc60
   __DATA_CONST.__objc_arraydata: 0xd60
   __AUTH_CONST.__auth_got: 0x2410
-  __AUTH_CONST.__auth_ptr: 0xb70
-  __AUTH_CONST.__const: 0xe088
-  __AUTH_CONST.__cfstring: 0x2a620
-  __AUTH_CONST.__objc_const: 0x422d0
+  __AUTH_CONST.__auth_ptr: 0xb88
+  __AUTH_CONST.__const: 0xe0b8
+  __AUTH_CONST.__cfstring: 0x2a720
+  __AUTH_CONST.__objc_const: 0x42198
   __AUTH_CONST.__objc_intobj: 0x1b30
   __AUTH_CONST.__objc_arrayobj: 0x438
   __AUTH_CONST.__objc_dictobj: 0xc8
   __AUTH_CONST.__objc_floatobj: 0x30
   __AUTH_CONST.__objc_doubleobj: 0x10
-  __AUTH.__objc_data: 0x7330
+  __AUTH.__objc_data: 0x7380
   __AUTH.__data: 0xb60
   __DATA.__objc_ivar: 0x1d80
-  __DATA.__data: 0xaa88
-  __DATA.__bss: 0x7678
+  __DATA.__data: 0xaa38
+  __DATA.__bss: 0x7680
   __DATA.__common: 0x90
   __DATA_DIRTY.__objc_data: 0x9c70
   __DATA_DIRTY.__data: 0x1588

   - /usr/lib/swift/libswiftsimd.dylib
   - /usr/lib/swift/libswiftsys_time.dylib
   - /usr/lib/swift/libswiftunistd.dylib
-  Functions: 20573
-  Symbols:   21679
-  CStrings:  25007
+  Functions: 20584
+  Symbols:   21690
+  CStrings:  25009
 
Symbols:
+ _OBJC_CLASS_$_WFGetCurrentAppAction
+ _OBJC_CLASS_$_WFVisibleAppManager
+ _OBJC_METACLASS_$_WFGetCurrentAppAction
CStrings:
+ "%!s(MISSING) We are using a Siri voice - let's use it. Assembled STS request %!@(MISSING)"
+ "@\"SiriTTSDaemonSession\""
+ "ActionKit52"
+ "Class getSiriTTSDaemonSessionClass(void)_block_invoke"
+ "Class getSiriTTSSpeechRequestClass(void)_block_invoke"
+ "Class getSiriTTSSynthesisVoiceClass(void)_block_invoke"
+ "Current (WFVisibleAppScope)"
+ "Current App"
+ "Current App (Output Name)"
+ "Get ${WFVisibleAppScope} app"
+ "Get ${WFVisibleAppScope} app (Parameter Summary)"
+ "Get ${WFVisibleAppScope} apps"
+ "Get ${WFVisibleAppScope} apps (Parameter Summary)"
+ "Get Current App"
+ "Get Current App (Action Name)"
+ "Gets the current visible app."
+ "Scope"
+ "Scope (WFVisibleAppScope)"
+ "SiriTTSDaemonSession"
+ "SiriTTSSpeechRequest"
+ "SiriTTSSynthesisVoice"
+ "T@\"SiriTTSDaemonSession\",R,N,V_stsSynthesizer"
+ "Visible"
+ "Visible (WFVisibleAppScope)"
+ "Visible Apps"
+ "Visible Apps (Output Name)"
+ "WFGetCurrentAppAction"
+ "WFVisibleAppScope"
+ "WFVisibleAppScope(Current)"
+ "WFVisibleAppScope(Visible)"
+ "_stsSynthesizer"
+ "actionDefinitionForGetCurrentAppAction"
+ "app.dashed"
+ "app|foreground|visible|topmost"
+ "finishWithApps:error:"
+ "getCurrentAppWithCompletionHandler:"
+ "getVisibleAppsWithCompletionHandler:"
+ "initWithLanguage:name:"
+ "initWithText:voice:"
+ "is.workflow.actions.getcurrentapp"
+ "rectangle.3.group"
+ "scopeState"
+ "softlink:r:path:/System/Library/PrivateFrameworks/SiriTTSService.framework/SiriTTSService"
+ "speakWithSpeechRequest:didFinish:"
+ "stsSpeechRequestForVoice:utterance:rate:pitch:intoFile:"
+ "stsSynthesizer"
+ "void *SiriTTSServiceLibrary(void)"
- "%!s(MISSING) voiced is available, and we are using a Siri voice - let's use it. Assembled VS request %!@(MISSING)"
- "@\"VSSpeechSynthesizer\""
- "Class getVSSpeechRequestClass(void)_block_invoke"
- "Class getVSSpeechSynthesizerClass(void)_block_invoke"
- "T@\"VSSpeechSynthesizer\",R,N,V_vsSynthesizer"
- "VSSpeechRequest"
- "VSSpeechSynthesizer"
- "VSSpeechSynthesizerDelegate"
- "VSVoiceAsset"
- "_vsSynthesizer"
- "gender"
- "outputPath"
- "setGender:"
- "setShouldCache:"
- "setVoiceName:"
- "softlink:r:path:/System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices"
- "speechSynthesizer:didContinueSpeakingRequest:"
- "speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:"
- "speechSynthesizer:didFinishPrewarmRequest:withError:"
- "speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:"
- "speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:"
- "speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:"
- "speechSynthesizer:didPauseSpeakingRequest:"
- "speechSynthesizer:didStartPresynthesizedAudioRequest:"
- "speechSynthesizer:didStartSpeakingRequest:"
- "speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:"
- "speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:"
- "speechSynthesizer:withRequest:didReceiveTimingInfo:"
- "speechSynthesizer:withSynthesisRequest:didGenerateAudioChunk:"
- "startSpeakingRequest:"
- "v32@0:8@\"VSSpeechSynthesizer\"16@\"VSPresynthesizedAudioRequest\"24"
- "v32@0:8@\"VSSpeechSynthesizer\"16@\"VSSpeechRequest\"24"
- "v40@0:8@\"VSSpeechSynthesizer\"16@\"VSSpeechRequest\"24@\"NSArray\"32"
- "v40@0:8@\"VSSpeechSynthesizer\"16@\"VSSpeechRequest\"24@\"NSError\"32"
- "v40@0:8@\"VSSpeechSynthesizer\"16@\"VSSpeechRequest\"24@\"VSAudioData\"32"
- "v40@0:8@\"VSSpeechSynthesizer\"16@\"VSSpeechRequest\"24@\"VSInstrumentMetrics\"32"
- "v44@0:8@\"VSSpeechSynthesizer\"16@\"VSPresynthesizedAudioRequest\"24B32@\"NSError\"36"
- "v44@0:8@16@24B32@36"
- "v48@0:8@\"VSSpeechSynthesizer\"16@\"VSPresynthesizedAudioRequest\"24@\"VSInstrumentMetrics\"32@\"NSError\"40"
- "v48@0:8@\"VSSpeechSynthesizer\"16@\"VSSpeechRequest\"24@\"VSInstrumentMetrics\"32@\"NSError\"40"
- "v48@0:8@\"VSSpeechSynthesizer\"16{_NSRange=QQ}24@\"VSSpeechRequest\"40"
- "v52@0:8@\"VSSpeechSynthesizer\"16@\"VSSpeechRequest\"24B32@\"NSString\"36@\"NSError\"44"
- "v52@0:8@16@24B32@36@44"
- "void *VoiceServicesLibrary(void)"
- "vsSpeechRequestForVoice:utterance:rate:pitch:intoFile:"
- "vsSynthesizer"

```
