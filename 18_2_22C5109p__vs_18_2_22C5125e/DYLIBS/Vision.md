## Vision

> `/System/Library/Frameworks/Vision.framework/Vision`

```diff

-8.0.51.0.0
-  __TEXT.__text: 0x3b4888
-  __TEXT.__auth_stubs: 0x41b0
-  __TEXT.__objc_methlist: 0x181cc
-  __TEXT.__cstring: 0x26a27
-  __TEXT.__swift5_typeref: 0x65fa
-  __TEXT.__const: 0x37b90
-  __TEXT.__swift5_reflstr: 0x4e6d
-  __TEXT.__swift5_assocty: 0x1278
-  __TEXT.__constg_swiftt: 0x572c
-  __TEXT.__swift5_fieldmd: 0x5cec
-  __TEXT.__swift5_builtin: 0x280
-  __TEXT.__swift5_proto: 0x1ffc
-  __TEXT.__swift5_types: 0xa38
-  __TEXT.__swift5_protos: 0x84
-  __TEXT.__swift5_capture: 0x304
+8.0.58.0.0
+  __TEXT.__text: 0x42ac94
+  __TEXT.__auth_stubs: 0x4ac0
+  __TEXT.__objc_methlist: 0x1826c
+  __TEXT.__cstring: 0x2bbff
+  __TEXT.__swift5_typeref: 0x81ec
+  __TEXT.__const: 0x3ed60
+  __TEXT.__swift5_reflstr: 0x6a9d
+  __TEXT.__swift5_assocty: 0x1568
+  __TEXT.__constg_swiftt: 0x8330
+  __TEXT.__swift5_fieldmd: 0x7bb8
+  __TEXT.__swift5_builtin: 0x2a8
+  __TEXT.__swift5_proto: 0x27cc
+  __TEXT.__swift5_types: 0xd04
+  __TEXT.__swift5_protos: 0x108
+  __TEXT.__oslogstring: 0x1ab
+  __TEXT.__swift5_capture: 0x5f0
   __TEXT.__swift5_mpenum: 0x30
-  __TEXT.__gcc_except_tab: 0x36c18
+  __TEXT.__gcc_except_tab: 0x36c1c
   __TEXT.__dlopen_cstrs: 0x51d
-  __TEXT.__oslogstring: 0x6
-  __TEXT.__unwind_info: 0x15ba8
-  __TEXT.__eh_frame: 0x7508
-  __TEXT.__objc_classname: 0x580b
-  __TEXT.__objc_methname: 0x2f332
-  __TEXT.__objc_methtype: 0x11937
-  __TEXT.__objc_stubs: 0x1aa20
-  __DATA_CONST.__got: 0x1890
-  __DATA_CONST.__const: 0x5e10
-  __DATA_CONST.__objc_classlist: 0x1580
+  __TEXT.__unwind_info: 0x18128
+  __TEXT.__eh_frame: 0xbe8c
+  __TEXT.__objc_classname: 0x5828
+  __TEXT.__objc_methname: 0x2f4f0
+  __TEXT.__objc_methtype: 0x11cbf
+  __TEXT.__objc_stubs: 0x1aaa0
+  __DATA_CONST.__got: 0x1948
+  __DATA_CONST.__const: 0x60f8
+  __DATA_CONST.__objc_classlist: 0x1678
   __DATA_CONST.__objc_catlist: 0xa8
   __DATA_CONST.__objc_protolist: 0x220
   __DATA_CONST.__objc_imageinfo: 0x8
-  __DATA_CONST.__objc_selrefs: 0x8188
+  __DATA_CONST.__objc_selrefs: 0x81b0
   __DATA_CONST.__objc_protorefs: 0x60
-  __DATA_CONST.__objc_superrefs: 0x1188
+  __DATA_CONST.__objc_superrefs: 0x1190
   __DATA_CONST.__objc_arraydata: 0xa38
-  __AUTH_CONST.__auth_got: 0x20f0
-  __AUTH_CONST.__auth_ptr: 0xb98
-  __AUTH_CONST.__const: 0x139d0
-  __AUTH_CONST.__cfstring: 0x195a0
-  __AUTH_CONST.__objc_const: 0x2fa20
+  __AUTH_CONST.__auth_got: 0x2578
+  __AUTH_CONST.__auth_ptr: 0x1290
+  __AUTH_CONST.__const: 0x184e0
+  __AUTH_CONST.__cfstring: 0x195c0
+  __AUTH_CONST.__objc_const: 0x317e0
   __AUTH_CONST.__objc_intobj: 0x1068
   __AUTH_CONST.__objc_arrayobj: 0x318
   __AUTH_CONST.__objc_floatobj: 0x2f0
   __AUTH_CONST.__objc_doubleobj: 0x120
   __AUTH_CONST.__objc_dictobj: 0x28
-  __AUTH.__objc_data: 0x7f10
-  __AUTH.__data: 0x5be8
-  __DATA.__objc_ivar: 0x1748
-  __DATA.__data: 0x6af8
-  __DATA.__bss: 0x41868
-  __DATA.__common: 0x2bd
+  __AUTH.__objc_data: 0x80a0
+  __AUTH.__data: 0x92c8
+  __DATA.__objc_ivar: 0x1758
+  __DATA.__data: 0x7a38
+  __DATA.__bss: 0x50270
+  __DATA.__common: 0x395
   __DATA_DIRTY.__objc_data: 0x5320
   __DATA_DIRTY.__data: 0x10
   __DATA_DIRTY.__bss: 0x34c

   - /usr/lib/swift/libswiftsimd.dylib
   - /usr/lib/swift/libswiftsys_time.dylib
   - /usr/lib/swift/libswiftunistd.dylib
-  Functions: 19744
-  Symbols:   13030
-  CStrings:  12937
+  Functions: 22918
+  Symbols:   13163
+  CStrings:  13429
 
Symbols:
+ _CRImageReaderKeepResourcesLoaded
+ _CVPixelBufferGetTypeID
+ _IOSurfaceGetAllocSize
+ _IOSurfaceGetTypeID
+ __os_signpost_emit_with_name_impl
+ __swiftEmptySetSingleton
+ _e5rt_buffer_object_create_from_iosurface
+ _e5rt_buffer_object_release
+ _e5rt_e5_compiler_compile
+ _e5rt_e5_compiler_create
+ _e5rt_e5_compiler_options_create
+ _e5rt_e5_compiler_options_release
+ _e5rt_e5_compiler_options_set_compute_device_types_mask
+ _e5rt_e5_compiler_release
+ _e5rt_error_code_get_string
+ _e5rt_execution_stream_create
+ _e5rt_execution_stream_encode_operation
+ _e5rt_execution_stream_execute_sync
+ _e5rt_execution_stream_operation_create_precompiled_compute_operation_with_options
+ _e5rt_execution_stream_operation_release
+ _e5rt_execution_stream_operation_retain_input_port
+ _e5rt_execution_stream_operation_retain_output_port
+ _e5rt_execution_stream_prewire_in_use_allocations
+ _e5rt_execution_stream_release
+ _e5rt_execution_stream_reset
+ _e5rt_execution_stream_submit_async
+ _e5rt_io_port_bind_buffer_object
+ _e5rt_io_port_bind_surface_object
+ _e5rt_io_port_is_surface
+ _e5rt_io_port_is_tensor
+ _e5rt_io_port_release
+ _e5rt_io_port_retain_surface_desc
+ _e5rt_io_port_retain_tensor_desc
+ _e5rt_precompiled_compute_op_create_options_create_with_program_function
+ _e5rt_precompiled_compute_op_create_options_release
+ _e5rt_program_function_get_extern_input_names
+ _e5rt_program_function_get_extern_output_names
+ _e5rt_program_function_get_num_extern_inputs
+ _e5rt_program_function_get_num_extern_outputs
+ _e5rt_program_function_release
+ _e5rt_program_library_create
+ _e5rt_program_library_get_function_metadata
+ _e5rt_program_library_get_function_names
+ _e5rt_program_library_get_num_functions
+ _e5rt_program_library_release
+ _e5rt_program_library_retain_program_function
+ _e5rt_surface_desc_get_format
+ _e5rt_surface_desc_get_height
+ _e5rt_surface_desc_get_width
+ _e5rt_surface_desc_release
+ _e5rt_surface_object_create_from_iosurface
+ _e5rt_tensor_desc_dtype_get_component_dtype
+ _e5rt_tensor_desc_dtype_get_component_size
+ _e5rt_tensor_desc_dtype_release
+ _e5rt_tensor_desc_get_shape
+ _e5rt_tensor_desc_get_size
+ _e5rt_tensor_desc_get_strides
+ _e5rt_tensor_desc_release
+ _e5rt_tensor_desc_retain_dtype
+ _objc_copyCppObjectAtomic
+ _swift_dynamicCastObjCClass
+ _swift_getDynamicType
+ _swift_isClassType
+ _swift_slowAlloc
+ _vImageRotate90_Planar8
CStrings:
+ "\noriginatingRequestDescriptor: "
+ " bytes instead of expected "
+ " bytes is not supported"
+ " bytes, which is smaller than expected "
+ " cannot be created"
+ " does not have a single input image"
+ " for identifier: "
+ " from FrameworkManager.manager.detectorDescriptorsCache: "
+ " has already been asigned"
+ " has not been bound"
+ " has unknown type"
+ " in NamedObjects is"
+ " in OptionsDictionary is not of unexpected type"
+ " in named objects collection"
+ " is expected to be CVPixelBuffer associated with IOSurface"
+ " is greater than allowed maximum "
+ " is less than required minimum "
+ " is not CVPixelBuffer"
+ " is not present in OptionsDictionary"
+ ". FrameworkManager.manager.detectorDescriptorsCache="
+ ". Operation failed due to attempt to buffer with wrong format (only kCVPixelFormatType_OneComponent8 is supported)"
+ ". Operation failed due to attempt to crop zero or near zero dimensioned area"
+ ". Should be kCVPixelFormatType_OneComponent8 ("
+ "35RT execution context must be prebound"
+ "35RT execution context must not be prebound"
+ ":  returning: object: "
+ ":  returning: removed object for identifier: "
+ ":  start, identifier: "
+ ":  start: inserting object: "
+ ": ObjectCacheCreationBlock: created programLibrary: "
+ ": There is no Data object with name: "
+ ": VisionResult initializer received obsedrvations==nil: "
+ ": after 'rowIndex in 0': cropRectWithin_inBufferDataStart:"
+ ": after E5RTUtils.ioPortType: outputPortType: "
+ ": after ValidationUtilities.originatingRequestDescriptor: "
+ ": after await performAll: resultStream: "
+ ": after getting functionDescriptor: "
+ ": after outputObjects.surface(associatedWith: "
+ ": after performAll: resultStream: "
+ ": after self.descriptor: inputDescriptor "
+ ": after self.descriptor: outputDescriptor "
+ ": after self.observationsFromE5RTExecutionOutputs: observations: "
+ ": after self.surface(associatedWith: "
+ ": after try await ImageRequestHandler: result: "
+ ": afterE5RTUtils.strings: self.lazyInputNames: "
+ ": assigning object with name: "
+ ": before 'rowIndex in 0': cropRectWithin_inBufferDataStart:"
+ ": before for outputName in outputNames: capacity: "
+ ": before outputObjects.surface(associatedWith: "
+ ": before return '(repeat try find(...)' results: "
+ ": before self.bindOutput for name: "
+ ": calling e5rt_execution_stream_prewire_in_use_allocations"
+ ": created inputImageDescriptor: "
+ ": e5rtExecutionContextNewIOSurfaceProperties: kIOSurfaceWidth: "
+ ": handling rotation: rotationDegrees: "
+ ": inputImageDescriptor: "
+ ": inside 'for await result in resultStream' error: "
+ ": inside 'for await result in resultStream' result: "
+ ": inside E5RTFunctionExecutionStreamOperationBlock"
+ ": inside for outputName in outputNames: outputName: "
+ ": inside objectData.withUnsafeBytes: rawBufferPointer: "
+ ": inside outputObjects.accessReadOnlyData: objectDataSize: "
+ ": object with name: "
+ ": processing results: result.notLookingAtScore: "
+ ": returning because self.cachedInputDescriptors != nil && self.cachedOutputDescriptors != nil: self.cachedInputDescriptors: "
+ ": rotatedCropRectInBufferCoordinatesPixelBuffer: "
+ ": rotatedCropRectInBufferCoordinates_vImage: "
+ ": start: from FaceObservation: faceObservation: "
+ ": tensorDescriptor: "
+ ";\nboundingBoxNormalizedToImage: "
+ ";\ncachedOutputDescriptors: "
+ ";\ncaptureQuality: "
+ ";\nconfidenceScoreType: "
+ ";\nfaceLivelinessScore: "
+ ";\nfaceScreenGaze: "
+ ";\nlazyInputNames: "
+ ";\noriginatingRequestDescriptor: "
+ ";\nregionOfInterest: "
+ ";\nrequestDescriptor: "
+ "; allowAssociatedObject: "
+ "; boundIOPorts: "
+ "; cachedInputDescriptors: "
+ "; description: Invalid model file URL"
+ "; description: Port with name "
+ "; description: Unexpected component type"
+ "; description: Unsupported surface format"
+ "; description: Wrong feature orientation"
+ "; description: Wrong image orientation"
+ "; difficultToSayScore: "
+ "; e5ModelFileURL: "
+ "; elementCount: "
+ "; executionContext: "
+ "; faceBoundingBox: "
+ "; inputDescriptors: "
+ "; inputImageDescriptor type: "
+ "; isUpperBodyOnly: "
+ "; kIOSurfaceAllocSize: "
+ "; kIOSurfaceBytesPerElement: "
+ "; kIOSurfaceHeight: "
+ "; lazyOutputNames: "
+ "; lengthInBytes: "
+ "; lookingAtScore: "
+ "; objectDataExpectedSize: "
+ "; originatingRequestDescriptor: "
+ "; outputDescriptor: "
+ "; outputDescriptors: "
+ "; outputObjects: "
+ "; overridingDeviceGazeScores: "
+ "; pointsClassification: "
+ "; processingDescriptorSpecifier: "
+ "; requiredClass: "
+ "; result.difficultToSayScore: "
+ "; result.lookingAtScore: "
+ "; self.cachedOutputDescriptors: "
+ "; smoothOutput: "
+ "; storageByteCount: "
+ "; upRightCropRectSize: "
+ "@132@0:8i16f20f24f28f32i36i40@44@52{CGRect={CGPoint=dd}{CGSize=dd}}60{CGSize=dd}92{vector<CGPoint, std::allocator<CGPoint>>=^{CGPoint}^{CGPoint}{__compressed_pair<CGPoint *, std::allocator<CGPoint>>=^{CGPoint}}}108"
+ "@32@0:8@16B24B28"
+ "A tensor element size of "
+ "Array object to be valudated is nil"
+ "At least one image dimension is zero: width: "
+ "Bound input and output objects must be both defined or both nil"
+ "CVPixelBufferRef"
+ "ComputeStageDeviceAssignments"
+ "DetectFaceRectanglesRequest is not supported in ExclaveKit"
+ "Detector (%!s(MISSING)): createDetector"
+ "Detector (%!s(MISSING), %!s(MISSING)) deallocated"
+ "Detector (%!s(MISSING), %!s(MISSING)): createRegionOfInterestCrop"
+ "Detector (%!s(MISSING), %!s(MISSING)): processRegionOfInterest"
+ "Detector: process"
+ "Division by zero"
+ "Division results in an overflow"
+ "Element size cannot be zero"
+ "Exception thrown while removing descriptor with identifier "
+ "Failed to create CVPixelBuffer object"
+ "Failed to lock IOSurfaceRef"
+ "Failed to to rotate vImage_Buffer with error: "
+ "Failed to to scale vImage_Buffer"
+ "Input face observation is a mandatory options and cannot be nil"
+ "Input human observation is a mandatory options and cannot be nil"
+ "Insufficient space allocated to copy string contents"
+ "Invalid Array element type"
+ "Invalid data type "
+ "Invalid face roll value: "
+ "Invalid version string: "
+ "Missing resource with name "
+ "Missing screen size property"
+ "Must have a valid input image descriptor"
+ "NamedObjects description is not available"
+ "NamedObjects.(#function): objects: "
+ "Network does not have head with identifier "
+ "Network does not have input "
+ "Network does not have output "
+ "Number of names should be equal to umber of objects"
+ "Object kind with "
+ "Object with identifier "
+ "Object with key "
+ "Object with name "
+ "ObjectCache description is not available"
+ "Port type is not initialized: "
+ "Provided URL is not a file URL"
+ "Rank cannot be zero"
+ "Session (%!s(MISSING)) created"
+ "Session (%!s(MISSING)) deallocated"
+ "Session acquired detector of type %!s(MISSING)"
+ "Session is releasing detector of type %!s(MISSING) with options %!s(MISSING)"
+ "SingleFaceTemporalGazeState object is not present in options dictionary"
+ "Sizes should be equal"
+ "Swift/ContiguousArrayBuffer.swift"
+ "Swift/IntegerTypes.swift"
+ "Swift/StringTesting.swift"
+ "Swift/StringUTF8View.swift"
+ "Swift/UnsafeBufferPointer.swift"
+ "Swift/UnsafePointer.swift"
+ "Swift/UnsafeRawPointer.swift"
+ "T@\"NSString\",R,N,V_weightsFilePath"
+ "TB,N,V_keepResourcesLoaded"
+ "TB,R,V_isRegularWeightsFile"
+ "TB,R,V_weightsFileExists"
+ "Tensor shape has multiple dimensions"
+ "TensorPlanar8Image"
+ "TensorPlanarFloat32Image"
+ "The type of object with key "
+ "There are no descriptors with identifier "
+ "There is no input descriptor with name "
+ "There is no output descriptor with name "
+ "T{vector<CGPoint, std::allocator<CGPoint>>=^{CGPoint}^{CGPoint}{__compressed_pair<CGPoint *, std::allocator<CGPoint>>=^{CGPoint}}},V_segmentation"
+ "Unexpected element size"
+ "Unexpected lables count"
+ "Unexpected screen size property: "
+ "Unexpectedly found nil while unwrapping an Optional value"
+ "Unknown error: observations==nil and error==nil passed to VisionResult initializer"
+ "Unknown input port type: "
+ "Unknown port type"
+ "UnsafeMutableBufferPointer with negative count"
+ "UnsafeMutablePointer.initialize overlapping range"
+ "UnsafeMutablePointer.initialize with negative count"
+ "UnsafeMutablePointer.moveInitialize with negative count"
+ "UnsafeMutableRawPointer.initializeMemory overlapping range"
+ "Unsupported orientation: "
+ "Unsupported pixel format: "
+ "VNCRImageReaderDetectorCreationOption_KeepResourcesLoaded"
+ "VNEspressoModelWeightsFileInfo"
+ "[Error] Interval already ended"
+ "_TtC6Vision11ImageBuffer"
+ "_TtC6Vision12E5RTFunction"
+ "_TtC6Vision12NamedObjects"
+ "_TtC6Vision13DetectorCache"
+ "_TtC6Vision17E5RTBasedDetector"
+ "_TtC6Vision18CameraGazeDetector"
+ "_TtC6Vision18CommonGazeDetector"
+ "_TtC6Vision18DeviceGazeDetector"
+ "_TtC6Vision18E5RTProgramLibrary"
+ "_TtC6Vision18ScreenGazeDetector"
+ "_TtC6Vision19TorsoPrintGenerator"
+ "_TtC6Vision20E5RTExecutionContext"
+ "_TtC6Vision20FaceAnalyzerDetector"
+ "_TtC6Vision23DetectCameraGazeRequest"
+ "_TtC6Vision23DetectDeviceGazeRequest"
+ "_TtC6Vision23DetectScreenGazeRequest"
+ "_TtC6Vision23E5RTExecutionBoundPorts"
+ "_TtC6Vision23ScreenGazeDetector_iPad"
+ "_TtC6Vision25ScreenGazeDetector_iPhone"
+ "_TtC6Vision27E5RTExecutionPrewarmedState"
+ "_TtC6Vision27FaceLivelinessScoreDetector"
+ "_TtC6Vision31FaceDetectorPerformingOperation"
+ "_TtC6Vision35CalculateFaceLivelinessScoreRequest"
+ "_TtC6Vision37CameraGazeDetectorPerformingOperation"
+ "_TtC6Vision37DeviceGazeDetectorPerformingOperation"
+ "_TtC6Vision37ScreenGazeDetectorPerformingOperation"
+ "_TtC6Vision38TorsoPrintGeneratorPerformingOperation"
+ "_TtC6Vision39FaceAnalyzerDetectorPerformingOperation"
+ "_TtC6Vision46FaceLivelinessScoreDetectorPerformingOperation"
+ "_TtC6Vision8Detector"
+ "_isRegularWeightsFile"
+ "_keepResourcesLoaded"
+ "_weightsFileExists"
+ "_weightsFilePath"
+ "accessReadOnlyData(for:accessBlock:)"
+ "accessReadOnlyData(for:accessBlock:): data is nil"
+ "accessReadOnlyData(for:accessBlock:): data is not nil; data: "
+ "accessReadOnlyData(for:accessBlock:): start: name: "
+ "allLandmarkPoints: "
+ "assign(_:objectKind:to:)"
+ "bindOutput(with:for:to:)"
+ "bindOutput(with:for:to:): before E5RTUtils.ioPortType"
+ "bindOutput(with:for:to:): before boundOutputPorts.recordPort"
+ "bindTensor(with:of:to:)"
+ "bindTensor(with:of:to:): start"
+ "boundInputObjects"
+ "boundInputPorts"
+ "boundOutputObjects"
+ "boundOutputPorts"
+ "buildDescriptorsCaches()"
+ "buildDescriptorsCaches(): input in inputs: input: "
+ "buildDescriptorsCaches(): inputs: "
+ "buildDescriptorsCaches(): output in outputs: output: "
+ "buildDescriptorsCaches(): self.inputs: "
+ "buildDescriptorsCaches(): self.outputs: "
+ "cachedInputDescriptors"
+ "cachedOutputDescriptors"
+ "calculateFaceLivelinessScore("
+ "calculateFaceLivelinessScoreRequest"
+ "camgaze_ek_fp16.bundle/camgaze_ek_fp16.mil"
+ "canceller"
+ "clientSharedMemoryRegion"
+ "com.apple.VisionLite"
+ "commonGazeResults(for:)"
+ "commonGazeResults(for:): start: outputObjects: "
+ "compilationOptions"
+ "computeVectorConnectedComponentSegmentation:minimumMaskPixelCount:withQueryID:"
+ "countProc call failed"
+ "createDetectorInternal(from:)"
+ "createDetectorInternal(from:): start: creating "
+ "createFaceObservationWithGazeScores(with:_:)"
+ "createFaceObservationWithGazeScores(with:_:): start: from DeviceGazeDetector"
+ "createFacePrint("
+ "createOperationExecutionStream(): returning operationHandle"
+ "createRegionOfInterestCrop(_:_:)"
+ "createRegionOfInterestCrop(_:_:): after imageBuffer.croppedBuffer"
+ "createRegionOfInterestCrop(_:_:): before imageBuffer.croppedBuffer"
+ "createRegionOfInterestCrop(_:_:): start"
+ "createTorsoPrint("
+ "cropCVPixelBuffer(_:_:_:_:_:_:_:_:)"
+ "cropCVPixelBuffer(_:_:_:_:_:_:_:_:): flipping horizontally"
+ "cropCVPixelBuffer(_:_:_:_:_:_:_:_:): flipping vertically"
+ "cropCVPixelBuffer(_:_:_:_:_:_:_:_:): inBuffer_vImage: "
+ "cropRect.size.height: "
+ "cropRect.size.width: "
+ "currentFrame"
+ "descriptor(for:_:_:_:_:_:)"
+ "descriptor(for:_:_:_:_:_:): after self.networkVersion"
+ "descriptor(for:_:_:_:_:_:): before E5RTInferenceFunctionDescriptor"
+ "descriptor(for:_:_:_:_:_:): before function.descriptor"
+ "descriptor(for:_:_:_:_:_:): created function: "
+ "descriptor(for:_:_:_:_:_:): created outputDescriptors: "
+ "descriptor(for:_:_:_:_:_:): start: "
+ "descriptor(forInput:)"
+ "descriptor(forInput:): after self.buildDescriptorsCaches"
+ "descriptor(forInput:): before self.buildDescriptorsCaches"
+ "detectCameraGaze("
+ "detectCameraGazeRequest"
+ "detectDeviceGaze("
+ "detectDeviceGazeRequest"
+ "detectScreenGaze("
+ "detectScreenGazeRequest"
+ "detectorCache"
+ "detectorCreation"
+ "detectorCropCreation"
+ "detectorCropProcessing"
+ "detectorDeallocated"
+ "detectorProcessing"
+ "detectors"
+ "devicegaze_ek_fp16.bundle/devicegaze_ek_fp16.mil"
+ "difficultToSayScore"
+ "e5rtExecutionContextNewIOSurfaceProperties()"
+ "e5rtExecutionInputs(for:_:options:): inputImageDescriptor: "
+ "e5rtFunctionDescriptor(for:)"
+ "e5rtFunctionDescriptor(for:): ObjectCacheCreationBlock; options: "
+ "e5rtProgramLibrary(for:): modelURL: "
+ "e5rt_buffer_object_create_from_iosurface call failed"
+ "e5rt_e5_compiler_compile call failed"
+ "e5rt_e5_compiler_create call failed"
+ "e5rt_e5_compiler_options_create call failed"
+ "e5rt_e5_compiler_options_set_compute_device_types_mask call failed"
+ "e5rt_execution_stream_create call failed"
+ "e5rt_execution_stream_encode_operation call failed"
+ "e5rt_execution_stream_execute_sync call failed"
+ "e5rt_execution_stream_operation_create_precompiled_compute_operation_with_options call failed"
+ "e5rt_execution_stream_operation_retain_input_port call failed"
+ "e5rt_execution_stream_operation_retain_output_port call failed"
+ "e5rt_execution_stream_prewire_in_use_allocations call failed"
+ "e5rt_execution_stream_reset call failed"
+ "e5rt_execution_stream_submit_async"
+ "e5rt_io_port_bind_buffer_object call failed"
+ "e5rt_io_port_bind_surface_object call failed"
+ "e5rt_io_port_is_surface call failed"
+ "e5rt_io_port_is_tensor call failed"
+ "e5rt_io_port_retain_surface_desc call failed"
+ "e5rt_io_port_retain_tensor_desc call failed"
+ "e5rt_precompiled_compute_op_create_options_create_with_program_function call failed"
+ "e5rt_program_library_create call failed"
+ "e5rt_program_library_get_function_metadata call failed"
+ "e5rt_program_library_retain_program_function call failed"
+ "e5rt_stream_completion_handler"
+ "e5rt_surface_desc_get_format call failed"
+ "e5rt_surface_desc_get_height call failed"
+ "e5rt_surface_desc_get_width call failed"
+ "e5rt_surface_object_create_from_iosurface call failed"
+ "e5rt_tensor_desc_dtype_get_component_dtype call failed"
+ "e5rt_tensor_desc_dtype_get_component_size call failed"
+ "e5rt_tensor_desc_get_shape call failed"
+ "e5rt_tensor_desc_get_size call failed"
+ "e5rt_tensor_desc_get_strides call failed"
+ "e5rt_tensor_desc_retain_dtype call failed"
+ "espressoModelWeightsFilePathInfoForConfigurationOptions:error:"
+ "exclaveANFR_v4md2"
+ "exclaveCameraGaze_v1md1"
+ "exclaveDeviceGaze_v1md1"
+ "exclaveLivelinessScore_v1md1"
+ "exclaveScreenGaze_v1md1"
+ "exclaveTorsoPrint_v5md2"
+ "execute(with:): after E5RTExecutionBoundPorts"
+ "execute(with:): after e5rt_execution_stream_execute_sync"
+ "execute(with:): after self.executePreflightBindings"
+ "execute(with:): before return: "
+ "execute(with:): start"
+ "executePreflightBindings(with:boundIOPorts:)"
+ "executePreflightBindings(with:boundIOPorts:): after function.outputs: "
+ "executePreflightBindings(with:boundIOPorts:): after self.validateIsNotPrebound()"
+ "executePreflightBindings(with:boundIOPorts:): before e5rt_execution_stream_encode_operation"
+ "executePreflightBindings(with:boundIOPorts:): before self.bindInput for name: "
+ "executePreflightBindings(with:boundIOPorts:): start"
+ "executionContext"
+ "executionStreamHandle"
+ "executionStreamOperationHandle"
+ "faceObjectState"
+ "faceObjectStates"
+ "faceliveliness_ek_fp16.bundle/faceliveliness_ek_fp16.mil"
+ "faceprint_ek_fp16.bundle/faceprint_ek_fp16.mil"
+ "featureOrientation: "
+ "featureOrientationRelativeToUpRight"
+ "functionDescriptor: "
+ "functionHandle"
+ "generateFacePrintRequest"
+ "generateTorsoPrintRequest"
+ "genericDetectorInitializationOptions(_:): added session to options: "
+ "humanObservations"
+ "imageOrientation: "
+ "init(from:overridingDeviceGazeScores:)"
+ "init(orientedImageSource:session:): TODO SK: exclave: what should I do here??"
+ "init(request:observations:error:)"
+ "init(with:): created new detector : "
+ "init(with:_:_:_:_:_:): exiting E5RTInferenceFunctionDescriptor"
+ "init(with:configuration:)"
+ "init(with:configuration:): configuration.prewireInUseAllocations = "
+ "init(with:configuration:): self.isPrebound = "
+ "initWithFilePath:exists:isRegular:"
+ "inputDescriptors"
+ "inputHumanObservations"
+ "inputImageBuffers"
+ "inputs: catch... self.lazyInputNames: "
+ "inputs: returning self.lazyInputNames: "
+ "invalid Collection: less than 'count' elements in collection"
+ "isPrebound"
+ "isProgramLibraryAtURL(_:): after e5rt_program_library_create"
+ "isProgramLibraryAtURL(_:): before e5rt_program_library_create"
+ "isProgramLibraryAtURL(_:): programLibraryPath: "
+ "isProgramLibraryAtURL(_:): returning false, errorCode: "
+ "isProgramLibraryAtURL(_:): returning true"
+ "isRegularWeightsFile"
+ "keepResourcesLoaded"
+ "lazyFunctionNames"
+ "lazyInputNames"
+ "lazyName"
+ "lazyOutputNames"
+ "modelBackingStore"
+ "modelComputeDevice"
+ "modelOutputCommonGazeProbabilitiesName"
+ "namedPorts"
+ "networkVersion(for:_:): after function.metadata: "
+ "networkVersion(for:_:): before function.metadata"
+ "normalizedScaledBoundingBox(for:)"
+ "notLookingAtScore"
+ "notLookingAtScore: "
+ "object(for:_:):  after try creationBlock for identifier: "
+ "object(for:_:):  before try creationBlock for identifier: "
+ "object(for:requiredClass:)"
+ "object(for:requiredClass:): start: name: "
+ "observationsFromE5RTExecutionOutputs(_:_:_:_:)"
+ "observationsFromE5RTExecutionOutputs(_:_:_:_:): newResult: "
+ "observationsFromE5RTExecutionOutputs(_:_:_:_:): outputFaceObservation: "
+ "observationsFromE5RTExecutionOutputs(_:_:_:_:): smoothedResult: "
+ "observationsFromE5RTExecutionOutputs(_:_:_:_:): start"
+ "origImageHeight"
+ "origImageWidth"
+ "origPixelBuffer"
+ "outputDescriptors"
+ "perform request: %!s(MISSING))"
+ "perform(_:): before 'result.observations as! T.Result'"
+ "perform(on:orientation:session:)"
+ "performAll: %!l(MISSING)d requests total"
+ "performScopedExecution(with:block:): after self.createOperationExecutionStream()"
+ "performScopedExecution(with:block:): before self.createOperationExecutionStream()"
+ "processRegionOfInterest(_:_:_:)"
+ "processRegionOfInterest(_:_:_:): after self.e5rtExecutionInputs"
+ "processRegionOfInterest(_:_:_:): after self.executionContext.execute"
+ "processRegionOfInterest(_:_:_:): start"
+ "programLibrary: "
+ "programLibraryHandle"
+ "removeAllObjects():  start: "
+ "removeAllObjects():  start: removed all: "
+ "removeObject(for:)"
+ "removeObject(for:):  start: removing object: identifier: "
+ "requestExecution"
+ "requestsExecution"
+ "runDetector(context:): after context.session.detector"
+ "runDetector(context:): after detector.process for face: "
+ "runDetector(context:): after detector.process for human: "
+ "runDetector(context:): before 'for face in faces'"
+ "runDetector(context:): before 'for human in humans'"
+ "runDetector(context:): before context.session.detector"
+ "runDetector(context:): final results: "
+ "screengaze_ek_ipad_fp16.bundle/screengaze_ek_ipad_fp16.mil"
+ "screengaze_ek_iphone_fp16.bundle/screengaze_ek_iphone_fp16.mil"
+ "self.validateIsPrebound"
+ "sessionAcquiredDetector"
+ "sessionCreated"
+ "sessionDeallocated"
+ "sessionReleasesDetector"
+ "setKeepResourcesLoaded:"
+ "stringProc call failed"
+ "supportedComputeStageDevices"
+ "surface(for:allowAssociatedObject:): start: name: "
+ "temporalSmoothingFrameCount: "
+ "torsoprint_ek_fp16.bundle/torsoprint_ek_fp16.mil"
+ "unknown data type"
+ "unknown pixel format type: "
+ "v28@?0Q8Q16i24"
+ "v40@0:8{vector<CGPoint, std::allocator<CGPoint>>=^{CGPoint}^{CGPoint}{__compressed_pair<CGPoint *, std::allocator<CGPoint>>=^{CGPoint}}}16"
+ "weightsFileExists"
+ "weightsFilePath"
+ "{CGRect={CGPoint=dd}{CGSize=dd}}44@0:8r^v16{CGSize=dd}24B40"
+ "{vector<CGPoint, std::allocator<CGPoint>>=\"__begin_\"^{CGPoint}\"__end_\"^{CGPoint}\"__end_cap_\"{__compressed_pair<CGPoint *, std::allocator<CGPoint>>=\"__value_\"^{CGPoint}}}"
+ "{vector<CGPoint, std::allocator<CGPoint>>=^{CGPoint}^{CGPoint}{__compressed_pair<CGPoint *, std::allocator<CGPoint>>=^{CGPoint}}}16@0:8"
+ "{vector<std::vector<CGPoint>, std::allocator<std::vector<CGPoint>>>=^v^v{__compressed_pair<std::vector<CGPoint> *, std::allocator<std::vector<CGPoint>>>=^v}}28@0:8@16i24"
+ "{vector<std::vector<CGPoint>, std::allocator<std::vector<CGPoint>>>=^v^v{__compressed_pair<std::vector<CGPoint> *, std::allocator<std::vector<CGPoint>>>=^v}}36@0:8@16Q24i32"
- " points, pointsClassification: "
- ", captureQuality: "
- "@116@0:8i16f20f24f28f32i36i40@44@52{CGRect={CGPoint=dd}{CGSize=dd}}60{CGSize=dd}92@108"
- "@28@0:8@16i24"
- "@36@0:8@16Q24i32"
- "FaceObservation("
- "HumanObservation(isUpperBodyOnly: "
- "T@\"NSArray\",&,V_segmentation"
- "computeConnectedComponentSegmentation:minimumMaskPixelCount:withQueryID:"
- "espressoModelWeightsFilePathForConfigurationOptions:error:"
- "objCType"
- "{CGPoint=dd}"
- "{CGRect={CGPoint=dd}{CGSize=dd}}44@0:8@16{CGSize=dd}24B40"

```
